
@article{yang2023diffusestylegesture,
	title={Diffusestylegesture: Stylized audio-driven co-speech gesture generation with diffusion models},
	author={Yang, Sicheng and Wu, Zhiyong and Li, Minglei and Zhang, Zhensong and Hao, Lei and Bao, Weihong and Cheng, Ming and Xiao, Long},
	journal={arXiv preprint arXiv:2305.04919},
	year={2023}
}

% ###########################################
% Survey
% ###########################################
@inproceedings{bergmann2011relation,
  title={The relation of speech and gestures: Temporal synchrony follows semantic synchrony},
  author={Bergmann, Kirsten and Aksu, Volkan and Kopp, Stefan},
  booktitle={Proceedings of the 2nd Workshop on Gesture and Speech in Interaction (GeSpIn 2011)},
  year={2011},
  keyword={}
}

% ###########################################
% Rule base
% ###########################################
@inproceedings{huang2012robot,
  title={Robot behavior toolkit: generating effective social behaviors for robots},
  author={Huang, Chien-Ming and Mutlu, Bilge},
  booktitle={Proceedings of the seventh annual ACM/IEEE international conference on Human-Robot Interaction},
  pages={25--32},
  year={2012},
    keyword={}
}

% ###########################################
% Statistic
% ###########################################
@incollection{levine2010gesture,
  title={Gesture controllers},
  author={Levine, Sergey and Kr{\"a}henb{\"u}hl, Philipp and Thrun, Sebastian and Koltun, Vladlen},
  booktitle={Acm siggraph 2010 papers},
  pages={1--11},
  publisher={ACM},
  year={2010},
}


% ###########################################
% Deep learning
% ##########################################

@article{neff2008gesture,
  title={Gesture modeling and animation based on a probabilistic re-creation of speaker style},
  author={Neff, Michael and Kipp, Michael and Albrecht, Irene and Seidel, Hans-Peter},
  journal={ACM Transactions On Graphics (TOG)},
  volume={27},
  number={1},
  pages={1--24},
  year={2008},
  publisher={ACM New York, NY, USA},
keyword={}
}

@inproceedings{chiu2015predicting,
  title={Predicting co-verbal gestures: A deep and temporal modeling approach},
  author={Chiu, Chung-Cheng and Morency, Louis-Philippe and Marsella, Stacy},
  booktitle={Intelligent Virtual Agents: 15th International Conference, IVA 2015, Delft, The Netherlands, August 26-28, 2015, Proceedings 15},
  pages={152--166},
  year={2015},
  organization={Springer},
keyword={}
}

@inproceedings{kucherenko2020gesticulator,
  title={Gesticulator: A framework for semantically-aware speech-driven gesture generation},
  author={Kucherenko, Taras and Jonell, Patrik and Van Waveren, Sanne and Henter, Gustav Eje and Alexandersson, Simon and Leite, Iolanda and Kjellstr{\"o}m, Hedvig},
  booktitle={Proceedings of the 2020 international conference on multimodal interaction},
  pages={242--250},
  year={2020},
  keyword={}
}


@inproceedings{bhattacharya2021speech2affectivegestures,
  title={Speech2affectivegestures: Synthesizing co-speech gestures with generative adversarial affective expression learning},
  author={Bhattacharya, Uttaran and Childs, Elizabeth and Rewkowski, Nicholas and Manocha, Dinesh},
  booktitle={Proceedings of the 29th ACM International Conference on Multimedia},
  pages={2027--2036},
  year={2021},
  keyword={}
}

@inproceedings{hasegawa2018evaluation,
  title={Evaluation of speech-to-gesture generation using bi-directional LSTM network},
  author={Hasegawa, Dai and Kaneko, Naoshi and Shirakawa, Shinichi and Sakuta, Hiroshi and Sumi, Kazuhiko},
  booktitle={Proceedings of the 18th International Conference on Intelligent Virtual Agents},
  pages={79--86},
  year={2018}
}


@inproceedings{bhattacharya2021text2gestures,
  title={Text2gestures: A transformer-based network for generating emotive body gestures for virtual agents},
  author={Bhattacharya, Uttaran and Rewkowski, Nicholas and Banerjee, Abhishek and Guhan, Pooja and Bera, Aniket and Manocha, Dinesh},
  booktitle={2021 IEEE virtual reality and 3D user interfaces (VR)},
  pages={1--10},
  year={2021},
  organization={IEEE}
}


@inproceedings{wu2021probabilistic,
  title={Probabilistic human-like gesture synthesis from speech using GRU-based WGAN},
  author={Wu, Bowen and Liu, Chaoran and Ishi, Carlos T and Ishiguro, Hiroshi},
  booktitle={Companion Publication of the 2021 International Conference on Multimodal Interaction},
  pages={194--201},
  year={2021}
}

@article{xu2022freeform,
  title={Freeform body motion generation from speech},
  author={Xu, Jing and Zhang, Wei and Bai, Yalong and Sun, Qibin and Mei, Tao},
  journal={arXiv preprint arXiv:2203.02291},
  year={2022}
}

@article{ekman1969repertoire,
  title={The repertoire of nonverbal behavior: Categories, origins, usage, and coding},
  author={Ekman, Paul and Friesen, Wallace V},
  journal={semiotica},
  volume={1},
  number={1},
  pages={49--98},
  year={1969},
  publisher={De Gruyter}
}

@book{sebeok2011advances,
  title={Advances in visual semiotics: The semiotic web 1992-93},
  author={Sebeok, Thomas A and Umiker-Sebeok, Jean},
  volume={118},
  year={2011},
  publisher={Walter de Gruyter}
}

@book{kipp2005gesture,
  title={Gesture generation by imitation: From human behavior to computer character animation},
  author={Kipp, Michael},
  year={2005},
  publisher={Universal-Publishers}
}

@book{webb1997linguistic,
  title={Linguistic features of metaphoric gestures},
  author={Webb, Rebecca A},
  year={1997},
  publisher={University of Rochester}
}


@article{mcclave1994gestural,
  title={Gestural beats: The rhythm hypothesis},
  author={McClave, Evelyn},
  journal={Journal of psycholinguistic research},
  volume={23},
  number={1},
  pages={45--66},
  year={1994},
  publisher={Springer}
}

@article{kingma2013auto,
  title={Auto-encoding variational bayes},
  author={Kingma, Diederik P and Welling, Max},
  journal={arXiv preprint arXiv:1312.6114},
  year={2013}
}


@article{starke2022deepphase,
  title={Deepphase: Periodic autoencoders for learning motion phase manifolds},
  author={Starke, Sebastian and Mason, Ian and Komura, Taku},
  journal={ACM Transactions on Graphics (TOG)},
  volume={41},
  number={4},
  pages={1--13},
  year={2022},
  publisher={ACM New York, NY, USA}
}

@inproceedings{yang2023qpgesture,
  title={QPGesture: Quantization-Based and Phase-Guided Motion Matching for Natural Speech-Driven Gesture Generation},
  author={Yang, Sicheng and Wu, Zhiyong and Li, Minglei and Zhang, Zhensong and Hao, Lei and Bao, Weihong and Zhuang, Haolin},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={2321--2330},
  year={2023}
}

@article{baevski2019vq,
  title={vq-wav2vec: Self-supervised learning of discrete speech representations},
  author={Baevski, Alexei and Schneider, Steffen and Auli, Michael},
  journal={arXiv preprint arXiv:1910.05453},
  year={2019}
}

@article{reimers2019sentence,
  title={Sentence-bert: Sentence embeddings using siamese bert-networks},
  author={Reimers, Nils and Gurevych, Iryna},
  journal={arXiv preprint arXiv:1908.10084},
  year={2019}
}


% ###########################################
% Fundemental paper
% ##########################################

@article{van2017neural,
  title={Neural discrete representation learning},
  author={Van Den Oord, Aaron and Vinyals, Oriol and others},
  journal={Advances in neural information processing systems},
  volume={30},
  year={2017}
}

@incollection{metallo2015scanning,
  title={Scanning and printing a 3D portrait of President Barack Obama},
  author={Metallo, Adam and Rossi, Vincent and Blundell, Jonathan and Waibel, G{\"u}nter and Graham, Paul and Fyffe, Graham and Yu, Xueming and Debevec, Paul},
  booktitle={SIGGRAPH 2015: Studio},
  pages={1--1},
  publisher={ACM},
  year={2015}
}

% ###########################################
% Diffusion Paper
% ##########################################


% [Ahuja et al., 2020] Chaitanya Ahuja, Dong Won Lee, Yukiko I. Nakano, and Louis-Philippe Morency. Style transfer for co-speech gesture animation: A multi-speaker conditional-mixture approach. In Computer Vision ECCV, volume 12363 of Lecture Notes in Computer Science, pages 248-265, 2020.
@inproceedings{ahuja2020style,
  title={Style transfer for co-speech gesture animation: A multi-speaker conditional-mixture approach},
  author={Ahuja, Chaitanya and Lee, Dong Won and Nakano, Yukiko I and Morency, Louis-Philippe},
  booktitle={Computer Vision ECCV},
  volume={12363},
  pages={248--265},
  year={2020},
  organization={Springer}
}

% [Alexanderson et al., 2020a] Simon Alexanderson, Gustav Eje Henter, Taras Kucherenko, and Jonas Beskow. Style-controllable speech-driven gesture synthesis using normalising flows. Comput. Graph. Forum, 39(2):487496, 2020.
@article{alexanderson2020style,
  title={Style-controllable speech-driven gesture synthesis using normalising flows},
  author={Alexanderson, Simon and Henter, Gustav Eje and Kucherenko, Taras and Beskow, Jonas},
  journal={Computer Graphics Forum},
  volume={39},
  number={2},
  pages={487--496},
  year={2020},
  publisher={Wiley Online Library}
}

% [Alexanderson et al., 2021] Simon Alexanderson, Éva Székely, Gustav Eje Henter, Taras Kucherenko, and Jonas Beskow. Generating coherent spontaneous speech and gesture from text. CoRR, abs/2101.05684, 2021.
@article{alexanderson2021generating,
  title={Generating coherent spontaneous speech and gesture from text},
  author={Alexanderson, Simon and Sz{\'e}kely, {\'E}va and Henter, Gustav Eje and Kucherenko, Taras and Beskow, Jonas},
  journal={CoRR},
  volume={abs/2101.05684},
  year={2021}
}


@inproceedings{alexanderson2020generating,
  title={Generating coherent spontaneous speech and gesture from text},
  author={Alexanderson, Simon and Sz{\'e}kely, {\'E}va and Henter, Gustav Eje and Kucherenko, Taras and Beskow, Jonas},
  booktitle={Proceedings of the 20th ACM International Conference on Intelligent Virtual Agents},
  pages={1--3},
  year={2020}
}

% [Alexanderson et al., 2022] Simon Alexanderson, Rajmund Nagy, Jonas Beskow, and Gustav Eje Henter. Listen, denoise, action! audio-driven motion synthesis with diffusion models. CoRR, abs/2211.09707, 2022.
@article{alexanderson2022listen,
  title={Listen, denoise, action! audio-driven motion synthesis with diffusion models},
  author={Alexanderson, Simon and Nagy, Rajmund and Beskow, Jonas and Henter, Gustav Eje},
  journal={CoRR},
  volume={abs/2211.09707},
  year={2022}
}


@article{ao2022rhythmic,
  title={Rhythmic gesticulator: Rhythm-aware co-speech gesture synthesis with hierarchical neural embeddings},
  author={Ao, Tenglong and Gao, Qingzhe and Lou, Yuke and Chen, Baoquan and Liu, Libin},
  journal={ACM Trans. Graph.},
  volume={41},
  number={6},
  pages={209:1--209:19},
  year={2022},
  publisher={ACM}
}

% [Beltagy et al., 2020] Iz Beltagy, Matthew E. Peters, and Arman Cohan. Longformer: The long-document transformer. CoRR, abs/2004.05150, 2020.
@article{beltagy2020longformer,
  title={Longformer: The long-document transformer},
  author={Beltagy, Iz and Peters, Matthew E and Cohan, Arman},
  journal={CoRR},
  volume={abs/2004.05150},
  year={2020}
}

@inproceedings{chang2022ivi,
  title={The ivi lab entry to the genea challenge 2022 - a tacotron2 based method for co-speech gesture generation with locality-constraint attention mechanism},
  author={Chang, Che-Jui and Zhang, Sen and Kapadia, Mubbasir},
  booktitle={Proceedings of the 2022 International Conference on Multimodal Interaction},
  pages={784--789},
  year={2022}
}

@article{chang2022unifying,
  title={Unifying human motion synthesis and style transfer with denoising diffusion probabilistic models},
  author={Chang, Ziyi and Findlay, Edmund JC and Zhang, Haozheng and Shum, Hubert PH},
  journal={arXiv preprint arXiv:2212.08526},
  year={2022}
}

% [Dabral et al., 2022] Rishabh Dabral, Muhammad Hamza Mughal, Vladislav Golyanik, and Christian Theobalt. Mofusion: A framework for denoising-diffusion-based motion synthesis. CoRR, abs/2212.04495, 2022.
@inproceedings{dabral2023mofusion,
  title={Mofusion: A framework for denoising-diffusion-based motion synthesis},
  author={Dabral, Rishabh and Mughal, Muhammad Hamza and Golyanik, Vladislav and Theobalt, Christian},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={9760--9770},
  year={2023}
}

% [Ghorbani et al., 2022] Saeed Ghorbani, Ylva Ferstl, Daniel Holden, Nikolaus F Troje, and Marc-André Carbonneau. Zeroeggs: Zero-shot example-based gesture generation from speech. arXiv preprint arXiv:2209.07556, 2022.
@misc{ghorbani2022zeroeggszeroshotexamplebasedgesture,
      title={ZeroEGGS: Zero-shot Example-based Gesture Generation from Speech}, 
      author={Saeed Ghorbani and Ylva Ferstl and Daniel Holden and Nikolaus F. Troje and Marc-André Carbonneau},
      year={2022},
      eprint={2209.07556},
      archivePrefix={arXiv},
      primaryClass={cs.GR},
      url={https://arxiv.org/abs/2209.07556}, 
}

% [Ginosar et al., 2019] Shiry Ginosar, Amir Bar, Gefen Kohavi, Caroline Chan, Andrew Owens, and Jitendra Malik. Learning individual styles of conversational gesture. In IEEE Conference on Computer Vision and Pattern Recognition, CVPR, pages 3497-3506, 2019.
@inproceedings{ginosar2019learning,
  title={Learning individual styles of conversational gesture},
  author={Ginosar, Shiry and Bar, Amir and Kohavi, Gefen and Chan, Caroline and Owens, Andrew and Malik, Jitendra},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={3497--3506},
  year={2019}
}

% [Habibie et al., 2021] Ikhsanul Habibie, Weipeng Xu, Dushyant Mehta, Lingjie Liu, Hans-Peter Seidel, Gerard Pons-Moll, Mohamed Elgharib, and Christian Theobalt Learning speech-driven $3 \mathrm{~d}$ conversational gestures from video. In IVA '21: ACM International Conference on Intelligent Virtual Agents, pages 101-108, 2021.
@inproceedings{habibie2021learning,
  title={Learning speech-driven 3d conversational gestures from video},
  author={Habibie, Ikhsanul and Xu, Weipeng and Mehta, Dushyant and Liu, Lingjie and Seidel, Hans-Peter and Pons-Moll, Gerard and Elgharib, Mohamed and Theobalt, Christian},
  booktitle={Proceedings of the 21st ACM International Conference on Intelligent Virtual Agents},
  pages={101--108},
  year={2021}
}

% [Habibie et al., 2022] Ikhsanul Habibie, Mohamed Elgharib, Kripasindhu Sarkar, Ahsan Abdullah, Simbarashe Nyatsanga, Michael Neff, and Christian Theobalt. A motion matching-based framework for controllable gesture synthesis from speech. In SIGGRAPH '22: Special Interest Group on Computer Graphics and Interactive Techniques Conference, pages 46:1-46:9, 2022.
@inproceedings{habibie2022motion,
  title={A motion matching-based framework for controllable gesture synthesis from speech},
  author={Habibie, Ikhsanul and Elgharib, Mohamed and Sarkar, Kripasindhu and Abdullah, Ahsan and Nyatsanga, Simbarashe and Neff, Michael and Theobalt, Christian},
  booktitle={ACM SIGGRAPH 2022 Conference Proceedings},
  pages={1--9},
  year={2022}
}

% [Ho and Salimans, 2022] Jonathan Ho and Tim Salimans. Classifier-free diffusion guidance. CoRR, abs/2207.12598, 2022.
@article{ho2022classifier,
  title={Classifier-free diffusion guidance},
  author={Ho, Jonathan and Salimans, Tim},
  journal={arXiv preprint arXiv:2207.12598},
  year={2022}
}

% [Ho et al., 2020] Jonathan Ho, Ajay Jain, and Pieter Abbeel. Denoising diffusion probabilistic models. Advances in Neural Information Processing Systems, 33:6840-6851, 2020.
@article{ho2020denoising,
  title={Denoising diffusion probabilistic models},
  author={Ho, Jonathan and Jain, Ajay and Abbeel, Pieter},
  journal={Advances in neural information processing systems},
  volume={33},
  pages={6840--6851},
  year={2020}
}

% [Huber, 1992] Peter J Huber. Robust estimation of a location parameter. In Breakthroughs in statistics, pages 492-518. 1992.
@incollection{huber1992robust,
  title={Robust estimation of a location parameter},
  author={Huber, Peter J},
  booktitle={Breakthroughs in statistics: Methodology and distribution},
  pages={492--518},
  year={1992},
  publisher={Springer}
}

% [Kim et al., 2022] Jihoon Kim, Jiseob Kim, and Sungjoon Choi. Flame: Free-form language-based motion synthesis \& editing. arXiv preprint arXiv:2209.00349, 2022.
@inproceedings{kim2023flame,
  title={Flame: Free-form language-based motion synthesis \& editing},
  author={Kim, Jihoon and Kim, Jiseob and Choi, Sungjoon},
  booktitle={Proceedings of the AAAI Conference on Artificial Intelligence},
  volume={37},
  pages={8255--8263},
  year={2023}
}

% [Kitaev et al., 2020] Nikita Kitaev, Lukasz Kaiser, and Anselm Levskaya. Reformer: The efficient transformer. In 8th International Conference on Learning Representations, ICLR April 26-30, 2020.
@article{kitaev2020reformer,
  title={Reformer: The efficient transformer},
  author={Kitaev, Nikita and Kaiser, {\L}ukasz and Levskaya, Anselm},
  journal={arXiv preprint arXiv:2001.04451},
  year={2020}
}

% [Kucherenko et al., 2021] Taras Kucherenko, Patrik Jonell, Youngwoo Yoon, Pieter Wolfert, and Gustav Eje Henter. A large, crowdsourced evaluation of gesture generation systems on common data: The GENEA challenge 2020. In IUI '21: 26th International Conference on Intelligent User Interfaces, April 13-17, pages 11-21, 2021.
@inproceedings{kucherenko2021large,
  title={A large, crowdsourced evaluation of gesture generation systems on common data: The GENEA Challenge 2020},
  author={Kucherenko, Taras and Jonell, Patrik and Yoon, Youngwoo and Wolfert, Pieter and Henter, Gustav Eje},
  booktitle={26th international conference on intelligent user interfaces},
  pages={11--21},
  year={2021}
}








% [Li et al., 2021b] Jing Li, Di Kang, Wenjie Pei, Xuefei Zhe, Ying Zhang, Zhenyu He, and Linchao Bao. Audio2gestures: Generating diverse gestures from speech audio with conditional variational autoencoders. In 2021
@inproceedings{li2021audio2gestures,
  title={Audio2gestures: Generating diverse gestures from speech audio with conditional variational autoencoders},
  author={Li, Jing and Kang, Di and Pei, Wenjie and Zhe, Xuefei and Zhang, Ying and He, Zhenyu and Bao, Linchao},
  booktitle={Proceedings of the IEEE/CVF International Conference on Computer Vision},
  pages={11293--11302},
  year={2021}
}

% [Li et al., 2022] Siyao Li, Weijiang Yu, Tianpei Gu, Chunze Lin, Quan Wang, Chen Qian, Chen Change Loy, and Ziwei Liu. Bailando: $3 \mathrm{~d}$ dance generation by actor-critic GPT with choreographic memory. In IEEE/CVF Conference on Computer Vision and Pattern Recognition, CVPR June 1824, pages 11040-11049, 2022.
@inproceedings{siyao2022bailando,
  title={Bailando: 3d dance generation by actor-critic gpt with choreographic memory},
  author={Siyao, Li and Yu, Weijiang and Gu, Tianpei and Lin, Chunze and Wang, Quan and Qian, Chen and Loy, Chen Change and Liu, Ziwei},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={11050--11059},
  year={2022}
}


% [Liang et al., 2022] Yuanzhi Liang, Qianyu Feng, Linchao Zhu, Li Hu, Pan Pan, and Yi Yang. SEEG: semantic energized co-speech gesture generation. In IEEE/CVF Conference on Computer Vision and Pattern Recognition, CVPR, pages 10463-10472, 2022.
@inproceedings{liang2022seeg,
  title={Seeg: Semantic energized co-speech gesture generation},
  author={Liang, Yuanzhi and Feng, Qianyu and Zhu, Linchao and Hu, Li and Pan, Pan and Yang, Yi},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={10473--10482},
  year={2022}
}

% [Lin et al., 2022] Zhenghao Lin, Yeyun Gong, Yelong Shen, Tong Wu, Zhihao Fan, Chen Lin, Weizhu Chen, and Nan Duan. GENIE: large scale pre-training for text generation with diffusion model. CoRR, abs/2212.11685, 2022.
@article{lin2022genie,
  title={Genie: Large scale pre-training for text generation with diffusion model},
  author={Lin, Zhenghao and Gong, Yeyun and Shen, Yelong and Wu, Tong and Fan, Zhihao and Lin, Chen and Chen, Weizhu and Duan, Nan},
  journal={arXiv preprint arXiv:2212.11685},
  year={2022}
}


% [Luvizon et al., 2023] Diogo Luvizon, Marc Habermann, Vladislav Golyanik, Adam Kortylewski, and Christian Theobalt. Scene-aware 3d multi-human motion capture from a single camera. CoRR, abs/2301.05175, 2023.
@inproceedings{luvizon2023scene,
  title={Scene-Aware 3D Multi-Human Motion Capture from a Single Camera},
  author={Luvizon, Diogo C and Habermann, Marc and Golyanik, Vladislav and Kortylewski, Adam and Theobalt, Christian},
  booktitle={Computer Graphics Forum},
  volume={42},
  number={2},
  pages={371--383},
  year={2023},
  organization={Wiley Online Library}
}

% [McGill et al., 1978] Robert McGill, John W Tukey, and Wayne A Larsen. Variations of box plots. The american statistician, 32(1):12-16, 1978.
@article{mcgill1978variations,
  title={Variations of box plots},
  author={McGill, Robert and Tukey, John W and Larsen, Wayne A},
  journal={The american statistician},
  volume={32},
  number={1},
  pages={12--16},
  year={1978},
  publisher={Taylor \& Francis}
}

% [Mei and Patel, 2022] Kangfu Mei and Vishal M. Patel. VIDM: video implicit diffusion models. CoRR, abs/2212.00235, 2022.
@inproceedings{mei2023vidm,
  title={Vidm: Video implicit diffusion models},
  author={Mei, Kangfu and Patel, Vishal},
  booktitle={Proceedings of the AAAI Conference on Artificial Intelligence},
  volume={37},
  number={8},
  pages={9117--9125},
  year={2023}
}


@inproceedings{nyatsanga2023comprehensive,
  title={A Comprehensive Review of Data-Driven Co-Speech Gesture Generation},
  author={Nyatsanga, Simbarashe and Kucherenko, Taras and Ahuja, Chaitanya and Henter, Gustav Eje and Neff, Michael},
  booktitle={Computer Graphics Forum},
  volume={42},
  number={2},
  pages={569--596},
  year={2023},
  organization={Wiley Online Library}
}

@article{rae2020transformers,
  title={Do transformers need deep long-range memory},
  author={Rae, Jack W and Razavi, Ali},
  journal={arXiv preprint arXiv:2007.03356},
  year={2020}
}

% [Ramesh et al., 2022] Aditya Ramesh, Prafulla Dhariwal, Alex Nichol, Casey Chu, and Mark Chen. Hierarchical text-conditional image generation with clip latents. arXiv preprint arXiv:2204.06125, 2022.
@article{ramesh2022hierarchical,
  title={Hierarchical text-conditional image generation with clip latents},
  author={Ramesh, Aditya and Dhariwal, Prafulla and Nichol, Alex and Chu, Casey and Chen, Mark},
  journal={arXiv preprint arXiv:2204.06125},
  volume={1},
  number={2},
  pages={3},
  year={2022}
}

% [Ren et al., 2022] Zhiyuan Ren, Zhihong Pan, Xin Zhou, and Le Kang. Diffusion motion: Generate text-guided 3d human motion by diffusion model. arXiv preprint arXiv:2210.12315, 2022.
@inproceedings{ren2023diffusion,
  title={Diffusion motion: Generate text-guided 3d human motion by diffusion model},
  author={Ren, Zhiyuan and Pan, Zhihong and Zhou, Xin and Kang, Le},
  booktitle={ICASSP 2023-2023 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)},
  pages={1--5},
  year={2023},
  organization={IEEE}
}

% [Roy et al., 2021] Aurko Roy. Efficient content-based sparse attention with routing transformers
@article{roy2021efficient,
  title={Efficient content-based sparse attention with routing transformers},
  author={Roy, Aurko and Saffar, Mohammad and Vaswani, Ashish and Grangier, David},
  journal={Transactions of the Association for Computational Linguistics},
  volume={9},
  pages={53--68},
  year={2021},
  publisher={MIT Press One Rogers Street Cambridge MA 02142-1209 USA journals-info}
}

% [Tevet et al., 2022] Guy Tevet, Sigal Raab, Brian Gordon, Yonatan Shafir, Daniel Cohen-Or, and Amit H Bermano. Human motion diffusion model. arXiv preprint arXiv:2209.14916, 2022.
@article{tevet2022human,
  title={Human motion diffusion model},
  author={Tevet, Guy and Raab, Sigal and Gordon, Brian and Shafir, Yonatan and Cohen-Or, Daniel and Bermano, Amit H},
  journal={arXiv preprint arXiv:2209.14916},
  year={2022}
}

% [Vaswani et al., 2017] Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan N Gomez, Łukasz Kaiser, and Illia Polosukhin. Attention is all you need. Advances in neural information processing systems, 30, 2017.
@article{vaswani2017attention,
  title={Attention is all you need},
  author={Vaswani, Ashish and Shazeer, Noam and Parmar, Niki and Uszkoreit, Jakob and Jones, Llion and Gomez, Aidan N and Kaiser, {\L}ukasz and Polosukhin, Illia},
  journal={Advances in neural information processing systems},
  volume={30},
  year={2017}
}

% [Xie et al., 2022] Pan Xie, Qipeng Zhang, Zexian Li, Hao Tang, Yao Du, and Xiaohui Hu. Vector quantized diffusion model with codeunet for text-to-sign pose sequences generation. arXiv preprint arXiv:2208.09141, 2022.
@article{xie2022vector,
  title={Vector quantized diffusion model with codeunet for text-to-sign pose sequences generation},
  author={Xie, Pan and Zhang, Qipeng and Li, Zexian and Tang, Hao and Du, Yao and Hu, Xiaohui},
  journal={arXiv preprint arXiv:2208.09141},
  year={2022}
}


% [Yang et al., 2022] The reprgesture entry to the GENEA challenge 2022. ICMI, November 7-11, pages 758-763, 2022.
@inproceedings{yang2022reprgesture,
  title={The ReprGesture entry to the GENEA Challenge 2022},
  author={Yang, Sicheng and Wu, Zhiyong and Li, Minglei and Zhao, Mengchen and Lin, Jiuxin and Chen, Liyang and Bao, Weihong},
  booktitle={Proceedings of the 2022 International Conference on Multimodal Interaction},
  pages={758--763},
  year={2022}
}


% [Yi et al., 2022] Hongwei Yi, Hualin Liang, Yifei Liu, Qiong Cao, Yandong Wen, Timo Bolkart, Dacheng Tao, and Michael J Black. Generating holistic 3d human motion from speech. arXiv preprint arXiv:2212.04420, 2022.
@inproceedings{yi2023generating,
  title={Generating holistic 3d human motion from speech},
  author={Yi, Hongwei and Liang, Hualin and Liu, Yifei and Cao, Qiong and Wen, Yandong and Bolkart, Timo and Tao, Dacheng and Black, Michael J},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={469--480},
  year={2023}
}

% [Yoon et al., 2019] Youngwoo Yoon, Woo-Ri Ko, Minsu Jang, Jaeyeon Lee, Jaehong Kim, and Geehyuk Lee. Robots learn social skills: End-to-end learning of cospeech gesture generation for humanoid robots. In International Conference on Robotics and Automation, ICRA, pages 4303-4309, 2019.
@inproceedings{yoon2019robots,
  title={Robots learn social skills: End-to-end learning of co-speech gesture generation for humanoid robots},
  author={Yoon, Youngwoo and Ko, Woo-Ri and Jang, Minsu and Lee, Jaeyeon and Kim, Jaehong and Lee, Geehyuk},
  booktitle={2019 International Conference on Robotics and Automation (ICRA)},
  pages={4303--4309},
  year={2019},
  organization={IEEE}
}

% [Yoon et al., 2020] Youngwoo Yoon, Bok Cha, Joo-Haeng Lee, Minsu Jang, Jaeyeon Lee, Jaehong Kim, and Geehyuk Lee. Speech gesture generation from the trimodal context of text, audio, and speaker identity. ACM Transactions on Graphics (TOG), 39(6):1-16, 2020.
@article{yoon2020speech,
  title={Speech gesture generation from the trimodal context of text, audio, and speaker identity},
  author={Yoon, Youngwoo and Cha, Bok and Lee, Joo-Haeng and Jang, Minsu and Lee, Jaeyeon and Kim, Jaehong and Lee, Geehyuk},
  journal={ACM Transactions on Graphics (TOG)},
  volume={39},
  number={6},
  pages={1--16},
  year={2020},
  publisher={ACM New York, NY, USA}
}

% [Yoon et al., 2022] Youngwoo Yoon, Pieter Wolfert, Taras Kucherenko, Carla Viegas, Teodor Nikolov, Mihail Tsakov, and Gustav Eje Henter. The GENEA challenge 2022: A large evaluation of data-driven co-speech gesture generation. In International Conference on Multimodal Interaction, ICMI, November 7-11, pages 736-747, 2022.
@inproceedings{yoon2022genea,
  title={The GENEA Challenge 2022: A large evaluation of data-driven co-speech gesture generation},
  author={Yoon, Youngwoo and Wolfert, Pieter and Kucherenko, Taras and Viegas, Carla and Nikolov, Teodor and Tsakov, Mihail and Henter, Gustav Eje},
  booktitle={Proceedings of the 2022 International Conference on Multimodal Interaction},
  pages={736--747},
  year={2022}
}

% [Yuan et al., 2022] Ye Yuan, Jiaming Song, Umar Iqbal, Arash Vahdat, and Jan Kautz. Physdiff: Physicsguided human motion diffusion model. arXiv preprint arXiv:2212.02500, 2022.
@inproceedings{yuan2023physdiff,
  title={Physdiff: Physics-guided human motion diffusion model},
  author={Yuan, Ye and Song, Jiaming and Iqbal, Umar and Vahdat, Arash and Kautz, Jan},
  booktitle={Proceedings of the IEEE/CVF International Conference on Computer Vision},
  pages={16010--16021},
  year={2023}
}


@article{zhang2022motiondiffuse,
	title={Motiondiffuse: Text-driven human motion generation with diffusion model},
	author={Zhang, Mingyuan and Cai, Zhongang and Pan, Liang and Hong, Fangzhou and Guo, Xinying and Yang, Lei and Liu, Ziwei},
	journal={arXiv preprint arXiv:2208.15001},
	year={2022}
}

% [Zhou et al., 2022] Chi Zhou, Tengyue Bian, and Kang Chen. Gesturemaster: Graph-based speech-driven gesture generation. In International Conference on Multimodal Interaction, ICMI, pages 764-770, 2022.
@inproceedings{zhou2022gesturemaster,
  title={Gesturemaster: Graph-based speech-driven gesture generation},
  author={Zhou, Chi and Bian, Tengyue and Chen, Kang},
  booktitle={Proceedings of the 2022 International Conference on Multimodal Interaction},
  pages={764--770},
  year={2022}
}

% Shenhan Qian, Zhi Tu, Yihao Zhi, Wen Liu, and Shenghua Gao. 2021. Speech Drives Templates: Co-Speech Gesture Synthesis with Learned Templates. In Proceedings of the IEEE/CVF International Conference on Computer Vision. 11077–11086.
@inproceedings{qian2021speech,
  title={Speech drives templates: Co-speech gesture synthesis with learned templates},
  author={Qian, Shenhan and Tu, Zhi and Zhi, Yihao and Liu, Wen and Gao, Shenghua},
  booktitle={Proceedings of the IEEE/CVF International Conference on Computer Vision},
  pages={11077--11086},
  year={2021}
}

% Andreas Aristidou, Anastasios Yiannakidis, Kfir Aberman, Daniel Cohen-Or, Ariel Shamir, and Yiorgos Chrysanthou. 2022. Rhythm is a Dancer: Music-Driven Motion Synthesis with Global Structure. IEEE Transactions on Visualization and Computer Graphics (2022), 1–1.
@article{aristidou2022rhythm,
  title={Rhythm is a dancer: Music-driven motion synthesis with global structure},
  author={Aristidou, Andreas and Yiannakidis, Anastasios and Aberman, Kfir and Cohen-Or, Daniel and Shamir, Ariel and Chrysanthou, Yiorgos},
  journal={IEEE Transactions on Visualization and Computer Graphics},
  volume={29},
  number={8},
  pages={3519--3534},
  year={2022},
  publisher={IEEE}
}


% The DiffuseStyleGesture+ entry to the GENEA Challenge 2023
@inproceedings{yang2022DiffuseStyleGestureplus,
	title={The DiffuseStyleGesture+ entry to the GENEA Challenge 2023},
	author={Sicheng Yang and Haiwei Xue and Zhensong Zhang and Minglei Li and Zhiyong Wu and Xiaofei Wu and Songcen Xu and Zonghong Dai},
	booktitle={Proceedings of the 2023 International Conference on Multimodal Interaction},
	year={2023}
}


@inproceedings{liu2022beat,
  title={Beat: A large-scale semantic and emotional multi-modal dataset for conversational gestures synthesis},
  author={Liu, Haiyang and Zhu, Zihao and Iwamoto, Naoya and Peng, Yichen and Li, Zhengqing and Zhou, You and Bozkurt, Elif and Zheng, Bo},
  booktitle={European conference on computer vision},
  pages={612--630},
  year={2022},
  organization={Springer}
}


@article{bello2005tutorial,
  title={A tutorial on onset detection in music signals},
  author={Bello, Juan Pablo and Daudet, Laurent and Abdallah, Samer and Duxbury, Chris and Davies, Mike and Sandler, Mark B},
  journal={IEEE Transactions on speech and audio processing},
  volume={13},
  number={5},
  pages={1035--1047},
  year={2005},
  publisher={IEEE}
}


@article{bojanowski2017enriching,
	title={Enriching word vectors with subword information},
	author={Bojanowski, Piotr and Grave, Edouard and Joulin, Armand and Mikolov, Tomas},
	journal={Transactions of the Association for Computational Linguistics},
	volume={5},
	pages={135--146},
	year={2017},
	publisher={MIT Press}
}

@misc{zhang2023adding,
	title={Adding Conditional Control to Text-to-Image Diffusion Models}, 
	author={Lvmin Zhang and Anyi Rao and Maneesh Agrawala},
	note={To appear in IEEE International Conference on Computer Vision (ICCV)},
	year={2023}
}

@misc{devlin2019bertpretrainingdeepbidirectional,
	title={BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding}, 
	author={Jacob Devlin and Ming-Wei Chang and Kenton Lee and Kristina Toutanova},
	year={2019},
	eprint={1810.04805},
	archivePrefix={arXiv},
	primaryClass={cs.CL},
	url={https://arxiv.org/abs/1810.04805}, 
}

@article{nagy2024towards,
	title={Towards a GENEA Leaderboard--an Extended, Living Benchmark for Evaluating and Advancing Conversational Motion Synthesis},
	author={Nagy, Rajmund and Voss, Hendric and Yoon, Youngwoo and Kucherenko, Taras and Nikolov, Teodor and Hoang-Minh, Thanh and McDonnell, Rachel and Kopp, Stefan and Neff, Michael and Henter, Gustav Eje},
	journal={arXiv preprint arXiv:2410.06327},
	year={2024}
}

@misc{edchrisjones,
  author       = {Chris Jones},
  title        = {Ed - Realistic Digital Human},
  year         = {2014},
  url          = {https://www.youtube.com/watch?v=HjHiC0mt4Ts},
  note         = {Accessed: 2024-11-18}
}


@article{weng2021diffusion,
	title   = "What are diffusion models?",
	author  = "Weng, Lilian",
	journal = "lilianweng.github.io",
	year    = "2021",
	month   = "Jul",
	url     = "https://lilianweng.github.io/posts/2021-07-11-diffusion-models/"
}

@misc{song2021score,
  author       = {Yang Song},
  title        = {Score-based Generative Modeling: A Brief Introduction},
  year         = {2021},
  url          = {https://yang-song.net/blog/2021/score/},
  note         = {Accessed: 2024-11-18}
}

@article{Chen_2022,
  title={WavLM: Large-Scale Self-Supervised Pre-Training for Full Stack Speech Processing},
  volume={16},
  ISSN={1941-0484},
  url={http://dx.doi.org/10.1109/JSTSP.2022.3188113},
  DOI={10.1109/jstsp.2022.3188113},
  number={6},
  journal={IEEE Journal of Selected Topics in Signal Processing},
  publisher={Institute of Electrical and Electronics Engineers (IEEE)},
  author={Chen, Sanyuan and Wang, Chengyi and Chen, Zhengyang and Wu, Yu and Liu, Shujie and Chen, Zhuo and Li, Jinyu and Kanda, Naoyuki and Yoshioka, Takuya and Xiao, Xiong and Wu, Jian and Zhou, Long and Ren, Shuo and Qian, Yanmin and Qian, Yao and Wu, Jian and Zeng, Michael and Yu, Xiangzhan and Wei, Furu},
  year={2022},
  month=oct, pages={1505-1518} 
}



@inproceedings{cassell1994animated,
	title={Animated conversation: rule-based generation of facial expression, gesture \& spoken intonation for multiple conversational agents},
	author={Cassell, Justine and Pelachaud, Catherine and Badler, Norman and Steedman, Mark and Achorn, Brett and Becket, Tripp and Douville, Brett and Prevost, Scott and Stone, Matthew},
	booktitle={Proceedings of the 21st annual conference on Computer graphics and interactive techniques},
	pages={413--420},
	year={1994}
}

@inproceedings{yang2020statistics,
	title={Statistics-based motion synthesis for social conversations},
	author={Yang, Yanzhe and Yang, Jimei and Hodgins, Jessica},
	booktitle={Computer Graphics Forum},
	volume={39},
	pages={201--212},
	year={2020},
	organization={Wiley Online Library}
}


@inproceedings{liu2022learning,
	title={Learning hierarchical cross-modal association for co-speech gesture generation},
	author={Liu, Xian and Wu, Qianyi and Zhou, Hang and Xu, Yinghao and Qian, Rui and Lin, Xinyi and Zhou, Xiaowei and Wu, Wayne and Dai, Bo and Zhou, Bolei},
	booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
	pages={10462--10472},
	year={2022}
}



@article{henter2020moglow,
	title={Moglow: Probabilistic and controllable motion synthesis using normalising flows},
	author={Henter, Gustav Eje and Alexanderson, Simon and Beskow, Jonas},
	journal={ACM Transactions on Graphics (TOG)},
	volume={39},
	number={6},
	pages={1--14},
	year={2020},
	publisher={ACM New York, NY, USA}
}


@article{kong2020diffwave,
	title={Diffwave: A versatile diffusion model for audio synthesis},
	author={Kong, Zhifeng and Ping, Wei and Huang, Jiaji and Zhao, Kexin and Catanzaro, Bryan},
	journal={arXiv preprint arXiv:2009.09761},
	year={2020}
}


@inproceedings{chen2024diffsheg,
	title={Diffsheg: A diffusion-based approach for real-time speech-driven holistic 3d expression and gesture generation},
	author={Chen, Junming and Liu, Yunfei and Wang, Jianan and Zeng, Ailing and Li, Yu and Chen, Qifeng},
	booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
	pages={7352--7361},
	year={2024}
}

@article{ao2023gesturediffuclip,
	title={Gesturediffuclip: Gesture diffusion model with clip latents},
	author={Ao, Tenglong and Zhang, Zeyi and Liu, Libin},
	journal={ACM Transactions on Graphics (TOG)},
	volume={42},
	number={4},
	pages={1--18},
	year={2023},
	publisher={ACM New York, NY, USA}
}


@inproceedings{yang2024freetalker,
	title={Freetalker: Controllable speech and text-driven gesture generation based on diffusion models for enhanced speaker naturalness},
	author={Yang, Sicheng and Xu, Zunnan and Xue, Haiwei and Cheng, Yongkang and Huang, Shaoli and Gong, Mingming and Wu, Zhiyong},
	booktitle={ICASSP 2024-2024 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)},
	pages={7945--7949},
	year={2024},
	organization={IEEE}
}

@article{saxon2020robust,
	title={Robust estimation of hypernasality in dysarthria with acoustic model likelihood features},
	author={Saxon, Michael and Tripathi, Ayush and Jiao, Yishan and Liss, Julie M and Berisha, Visar},
	journal={IEEE/ACM transactions on audio, speech, and language processing},
	volume={28},
	pages={2511--2522},
	year={2020},
	publisher={IEEE}
}

@inproceedings{nichol2021improved,
	title={Improved denoising diffusion probabilistic models},
	author={Nichol, Alexander Quinn and Dhariwal, Prafulla},
	booktitle={International conference on machine learning},
	pages={8162--8171},
	year={2021},
	organization={PMLR}
}

@article{dhariwal2021diffusion,
	title={Diffusion models beat gans on image synthesis},
	author={Dhariwal, Prafulla and Nichol, Alexander},
	journal={Advances in neural information processing systems},
	volume={34},
	pages={8780--8794},
	year={2021}
}